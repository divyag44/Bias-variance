{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78988828-8148-4d9d-b4af-4921f0f23c6f",
   "metadata": {},
   "source": [
    "# Q1 Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b9811-8e9f-434f-bf17-8eea48d28bd0",
   "metadata": {},
   "source": [
    "## (Ans) Overfitting means good training but less accuracy, so low bias and high variance while in underfitting the model is trained not with good accuracy and test is also almost equivallent to training, there we have low bias and variance. The difference in both comes up with there level of accuracy and it affects the biasedness and variance of model. It can be mitigated by rightly training and testing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd659ff-0a1a-4fd7-bd64-6f4444a08429",
   "metadata": {},
   "source": [
    "# Q2 How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe37b20-dca3-4c8d-acdc-2e1d54a6900a",
   "metadata": {},
   "source": [
    "## (Ans) To reduce overfitting we should keep training the data better while we also check it's accuracy. We have to lower it's variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb840c-196b-4194-9e1a-76fc1231bf1a",
   "metadata": {},
   "source": [
    "# Q3 Explain underfitting. List scenarios where underfitting can occur in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c87a60-37e6-4a16-915b-8d76d30afc58",
   "metadata": {},
   "source": [
    "## (Ans)  In underfitting the model is trained not with good accuracy and test is also almost equivallent to training, there we have low bias and variance. The difference in both comes up with there level of accuracy and it affects the biasedness and variance of model. It can be mitigated by rightly training and testing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b1166-2736-4d74-b9a1-f34d937559f5",
   "metadata": {},
   "source": [
    "# Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd41c8-2849-4a4f-8959-0b8616445483",
   "metadata": {},
   "source": [
    "## (Ans)  Certain algorithms inherently have a high bias and low variance and vice-versa. If a model uses a simple machine learning algorithm like in the case of a linear model in the above code, the model will have high bias and low variance (underfitting the data). If a model follows a complex machine learning model, then it will have high variance and low bias ( overfitting the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a25b29-dee0-4f35-b5a5-fcb76a09215e",
   "metadata": {},
   "source": [
    "# Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e7688-cb27-474c-98a9-014ab9355ed0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## (Ans) Overfitting:\n",
    "\n",
    "## Validation loss starts increasing while training loss continues to decrease. Poor generalization on the validation/test set compared to the training set. High variance in performance across different cross-validation folds.\n",
    "\n",
    "## Underfitting:\n",
    "\n",
    "## Both training and validation loss remain high and plateau. Low performance on both training and validation/test sets. High bias in performance across different cross-validation folds.\n",
    "\n",
    "## To determine whether your model is overfitting or underfitting, you need to observe the performance metrics, plot the relevant curves, and analyze the behavior of the model during training and evaluation stages. Adjusting hyperparameters, collecting more data, or using different algorithms or architectures can help address these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb751eeb-9c98-49be-a489-cf08d4a78823",
   "metadata": {},
   "source": [
    "# Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias  and high variance models, and how do they differ in terms of their performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b313d12-54a8-4a15-975d-d21e1198e6a3",
   "metadata": {},
   "source": [
    "## (Ans) Bias:\n",
    "\n",
    "## Bias represents the error introduced by approximating a real problem with a simplified model. A high bias model tends to underfit the data, meaning it fails to capture the underlying patterns in the training data and performs poorly on both the training and test/validation data. Examples of high bias models include linear regression with insufficient features to capture the complexity of the data or a simple decision tree with limited depth for a complex dataset. \n",
    "\n",
    "## Variance:\n",
    "\n",
    "## Variance refers to the sensitivity of a model to fluctuations in the training data. A high variance model tends to overfit the data, meaning it memorizes the noise in the training set rather than learning the general patterns, resulting in excellent performance on the training data but poor performance on new, unseen data. Examples of high variance models include complex deep neural networks with too many layers or decision trees with a high depth that can perfectly fit the training data but struggle to generalize to new examples.\n",
    "\n",
    "## example of high bias and high variance model\n",
    "\n",
    "## Consider weight and height model, if we train the model and it is not trained properly and it gives bad figures or curves,then it has high bias (not trained properly), and if we test the model after training it, then the result it gives is less accurate, so it has high variance(trained good but not good test results). so the weight & height model fails here due to underfitting.\n",
    "\n",
    "\n",
    "## performance difference\n",
    "\n",
    "## Performance Differences: High bias models have low training and validation/test performance and generally exhibit poor generalization. High variance models have high training performance but significantly lower validation/test performance, indicating they fail to generalize well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf9eea-3451-4ba9-aa4e-8f8b8100e49d",
   "metadata": {},
   "source": [
    "# Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407b6040-d430-4ebc-9d26-e8689427e273",
   "metadata": {},
   "source": [
    "## (Ans) Regularization in machine learning is a set of techniques used to prevent overfitting and improve model generalization by adding a penalty term to the loss function during training.\n",
    "\n",
    "## How regularization prevents overfitting:\n",
    "\n",
    "## Regularization introduces a penalty for large weights or complex model structures, discouraging the model from relying too heavily on individual features and making it less prone to overfitting.\n",
    "\n",
    "## Common regularization techniques:\n",
    "\n",
    "## L1 Regularization (Lasso):\n",
    "\n",
    "## Adds the absolute value of the weights as a penalty term to the loss function. Encourages sparsity, as some weights may become exactly zero, effectively removing features from the model. Helps in feature selection by automatically identifying less relevant features.\n",
    "\n",
    "## L2 Regularization (Ridge):\n",
    "\n",
    "## Adds the square of the weights as a penalty term to the loss function. Discourages large weights but rarely forces them to be exactly zero. Helps in feature shrinkage, reducing the impact of less important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace877d-0c25-45b5-92a8-4f06de7210be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
